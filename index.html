<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Autodebug to assess LLM hallucinations">
  <meta name="keywords" content="LLM, Adversarial Attack, Hallucination">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--   <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>  -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/bug-512.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.xiaodongyu.me/home">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://autodebug-llm.github.io">
            AutoDebug
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.xiaodongyu.me/home">Xiaodong Yu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/hcheng2site">Hao Cheng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/xiaodl/">Xiaodong Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cis.upenn.edu/~danroth/">Dan Roth</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.microsoft.com/en-us/research/people/jfgao/">Jianfeng Gao</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Pennsylvania,</span>
            <span class="author-block"><sup>2</sup>Microsoft Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.12516.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.12516"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Although remarkable progress has been achieved in preventing large language
            model (LLM) hallucinations using instruction tuning and retrieval augmentation,
            it remains challenging to measure the reliability of LLMs using human-crafted
            evaluation data which is not available for many tasks and domains and could suffer from data leakage. Inspired by adversarial machine learning, this paper aims
            to develop a method of automatically generating evaluation data by appropriately
            modifying existing data on which LLMs behave faithfully. Specifically, this paper presents AutoDebug, an LLM-based framework to use prompting chaining
            to generate transferable adversarial attacks in the form of question-answering examples. We seek to understand the extent to which these examples trigger the
            hallucination behaviors of LLMs.
          </p>
          <p>
            We implement AutoDebug using ChatGPT and evaluate the resulting two variants of a popular open-domain question-answering dataset, Natural Questions (NQ), on a collection of open-source and proprietary LLMs under various prompt-
            ing settings. Our generated evaluation data is human-readable and, as we show,
            humans can answer these modified questions well. Nevertheless, we observe pronounced accuracy drops across multiple LLMs including GPT-4. Our experimental results show that LLMs are likely to hallucinate in two categories of question-
            answering scenarios where (1) there are conflicts between knowledge given in the
            prompt and their parametric knowledge, or (2) the knowledge expressed in the
            prompt is complex. Finally, we find that the adversarial examples generated by
            our method are transferable across all considered LLMs. The examples generated
            by a small model can be used to debug a much larger model, making our approach
            cost-effective
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@article{yu2023automatic,
      author    = {Yu, Xiaodong and Cheng, Hao and Liu, Xiaodong and Roth, Dan and Gao, Jianfeng},
      title     = {Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks},
      journal   = {arXiv preprint},
      year      = {2023}
    }</code></pre>
  </div>
</section>

<!-- <section>
  <div class="section" id="org-banners" style="display:flex">
    <a href="https://cogcomp.seas.upenn.edu/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/upenn.jpg">
    </a>
    <a href="https://www.microsoft.com/en-us/research/" target="_blank" rel="external">
        <img class="center-block org-banner" src="static/images/MSR_logo_2.webp">
    </a>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
<!--     <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
            licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
